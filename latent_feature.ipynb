{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae19951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luao/software/miniconda3/envs/retfound/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1404212250>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import models_vit as models\n",
    "from huggingface_hub import hf_hub_download\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c3d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(chkpt_dir, arch='RETFound_mae'):\n",
    "    \n",
    "    # load model\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
    "    \n",
    "    # build model\n",
    "    if arch=='RETFound_mae':\n",
    "        model = models.__dict__[arch](\n",
    "            img_size=224,\n",
    "            num_classes=2,\n",
    "            drop_path_rate=0,\n",
    "            global_pool=True,\n",
    "        )\n",
    "        msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    else:\n",
    "        model = models.__dict__[arch](\n",
    "            num_classes=2,\n",
    "            drop_path_rate=0,\n",
    "            args=None,\n",
    "        )\n",
    "        msg = model.load_state_dict(checkpoint['teacher'], strict=False)\n",
    "    return model\n",
    "\n",
    "def run_one_image(img, model, arch):\n",
    "    \n",
    "    x = torch.tensor(img)\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    x = torch.einsum('nhwc->nchw', x)\n",
    "    \n",
    "    x = x.to(device, non_blocking=True)\n",
    "    latent = model.forward_features(x.float())\n",
    "    \n",
    "    if arch=='dinov2_large':\n",
    "        latent = latent[:, 1:, :].mean(dim=1,keepdim=True)\n",
    "        latent = nn.LayerNorm(latent.shape[-1], eps=1e-6).to(device)(latent)\n",
    "    \n",
    "    latent = torch.squeeze(latent)\n",
    "    return latent\n",
    "\n",
    "def run_one_image_for_prediction(img, model, arch): # not sure about this: 还没有写如果是dinov2_large的情况\n",
    "\n",
    "    x = torch.tensor(img)\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    x = torch.einsum('nhwc->nchw', x)\n",
    "    \n",
    "    x = x.to(device, non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(x.float())\n",
    "        probs = torch.softmax(predictions, dim=1)\n",
    "        pred_class = torch.argmax(probs, dim=1).item()\n",
    "        probs_pred_class = probs[0][pred_class].item()\n",
    "        probs_1_class = probs[0][1].item()\n",
    "    \n",
    "    return {\n",
    "        'score_raw' : predictions.cpu().numpy(), # raw score before softmax: shape通常是(1, num_classes)\n",
    "        'prob_all' : probs.cpu().numpy(),        # probabilities: shape通常是(1, num_classes)\n",
    "        'pred_class': pred_class,                # predicted class: int\n",
    "        'pred_class_prob': probs_pred_class,     # probability of predicted class: float\n",
    "        'pred_1class_prob': probs_1_class        # probability of class 1: float\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a250363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(data_path,\n",
    "                chkpt_dir,\n",
    "                device,\n",
    "                arch='RETFound_mae'):\n",
    "    # loading model\n",
    "    model_ = prepare_model(chkpt_dir, arch)\n",
    "    model_.to(device)\n",
    "\n",
    "    img_list = os.listdir(data_path)\n",
    "    \n",
    "    name_list, feature_list = [], []\n",
    "    score_raw_list, prob_all_list, pred_class_list, pred_class_prob_list, pred_1class_prob_list = [], [], [], [], [] # we added this\n",
    "\n",
    "    model_.eval()\n",
    "    \n",
    "    finished_num = 0\n",
    "    for i in img_list:\n",
    "        finished_num+=1\n",
    "        if (finished_num%1000 == 0):\n",
    "            print(str(finished_num)+\"finished\")\n",
    "        \n",
    "        # img = Image.open(os.path.join(data_path, i))\n",
    "        img = Image.open(os.path.join(data_path, i)).convert('RGB')\n",
    "\n",
    "        img = img.resize((224, 224))\n",
    "        img = np.array(img) / 255.\n",
    "        \n",
    "        img[...,0] = (img[...,0] - img[...,0].mean())/img[...,0].std()\n",
    "        img[...,1] = (img[...,1] - img[...,1].mean())/img[...,1].std()\n",
    "        img[...,2] = (img[...,2] - img[...,2].mean())/img[...,2].std()\n",
    "        assert img.shape == (224, 224, 3)\n",
    "        \n",
    "        latent_feature = run_one_image(img, model_, arch) # latent_feature\n",
    "        pred_dict = run_one_image_for_prediction(img, model_, arch)\n",
    "\n",
    "        name_list.append(i)\n",
    "        feature_list.append(latent_feature.detach().cpu().numpy())\n",
    "\n",
    "        score_raw_list.append(pred_dict['score_raw'])               # numpy array (1, num_classes)\n",
    "        prob_all_list.append(pred_dict['prob_all'])                 # numpy array (1, num_classes)\n",
    "        pred_class_list.append(pred_dict['pred_class'])             # int\n",
    "        pred_class_prob_list.append(pred_dict['pred_class_prob'])   # float\n",
    "        pred_1class_prob_list.append(pred_dict['pred_1class_prob']) # float\n",
    "        \n",
    "    return (\n",
    "        name_list, \n",
    "        feature_list, \n",
    "        score_raw_list, \n",
    "        prob_all_list, \n",
    "        pred_class_list, \n",
    "        pred_class_prob_list, \n",
    "        pred_1class_prob_list\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54acfcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chkpt_dir = hf_hub_download(repo_id=\"YukunZhou/RETFound_dinov2_meh\", filename=\"RETFound_dinov2_meh.pth\")\n",
    "chkpt_dir = \"/mnt/d/3.dlProject/bdrv/output/LEO/1.RETFound_mae_natureOCT0.cwflmix-bdrv/output_dir/1.RETFound_mae_natureOCT0.cwflmix-bdrv/checkpoint-best.pth\"\n",
    "output_path = \"/mnt/d/3.dlProject/bdrv/output/LEO/1.RETFound_mae_natureOCT0.cwflmix-bdrv/output_dir/1.RETFound_mae_natureOCT0.cwflmix-bdrv/feature.csv\"\n",
    "data_path = \"/mnt/d/3.dlProject/bdrv/data/retinal_vasculitis_crop/test/bd\"\n",
    "device = torch.device('cuda')\n",
    "arch='RETFound_mae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0d13a7-2b46-40eb-ab48-5f90a6aeecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking up to 10 images from /mnt/d/3.dlProject/bdrv/data/retinal_vasculitis_crop/test/bd\n",
      "[1] 1209_2013.3.19_od_1.png: mode=L, shape=(496, 768), size=(768, 496)\n",
      "[2] 1209_2013.3.19_od_2.png: mode=L, shape=(496, 768), size=(768, 496)\n",
      "[3] 1517_2019.1.2_os_1.jpg: mode=L, shape=(496, 768), size=(768, 496)\n",
      "[4] 1517_2019.1.2_os_2.jpg: mode=L, shape=(496, 768), size=(768, 496)\n",
      "[5] 174_2013.8.8_od_1.png: mode=L, shape=(496, 768), size=(768, 496)\n",
      "[6] 174_2013.8.8_od_2.png: mode=L, shape=(496, 768), size=(768, 496)\n",
      "[7] 174_2013.8.8_os_1.png: mode=L, shape=(496, 768), size=(768, 496)\n",
      "[8] 174_2013.8.8_os_2.png: mode=L, shape=(496, 768), size=(768, 496)\n",
      "[9] 603_2016.4.12_od_1.jpg: mode=L, shape=(496, 768), size=(768, 496)\n",
      "[10] 603_2016.4.12_od_2.jpg: mode=L, shape=(496, 768), size=(768, 496)\n"
     ]
    }
   ],
   "source": [
    "# # Diagnostic cell: check image formats in the dataset\n",
    "# def check_image_formats(data_path, max_samples=10):\n",
    "#     img_list = os.listdir(data_path)\n",
    "#     if len(img_list) > max_samples:\n",
    "#         img_list = img_list[:max_samples]  # Check only a few images\n",
    "    \n",
    "#     print(f\"Checking up to {max_samples} images from {data_path}\")\n",
    "#     for i, img_name in enumerate(img_list):\n",
    "#         try:\n",
    "#             img_path = os.path.join(data_path, img_name)\n",
    "#             img = Image.open(img_path)\n",
    "#             img_array = np.array(img)\n",
    "#             print(f\"[{i+1}] {img_name}: mode={img.mode}, shape={img_array.shape}, size={img.size}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"[{i+1}] {img_name}: Error - {str(e)}\")\n",
    "    \n",
    "# # Run this before processing to check your images\n",
    "# check_image_formats(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0296f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    name_list, \n",
    "    feature_list, \n",
    "    score_raw_list, \n",
    "    prob_all_list, \n",
    "    pred_class_list, \n",
    "    pred_class_prob_list, \n",
    "    pred_1class_prob_list\n",
    ") = get_feature(data_path, chkpt_dir, device, arch=arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29da844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features to /mnt/d/3.dlProject/bdrv/output/LEO/1.RETFound_mae_natureOCT0-bdrv/output_dir/1.RETFound_mae_natureOCT0-bdrv/feature.csv\n"
     ]
    }
   ],
   "source": [
    "df_info = pd.DataFrame({\n",
    "    \"name\": name_list,\n",
    "    \"score_raw\": score_raw_list,\n",
    "    \"prob_all\": prob_all_list,\n",
    "    \"pred_class\": pred_class_list,\n",
    "    \"pred_class_prob\": pred_class_prob_list,\n",
    "    \"pred_1class_prob\": pred_1class_prob_list\n",
    "})\n",
    "\n",
    "df_feature = pd.DataFrame(\n",
    "    feature_list, \n",
    "    columns = [\"feature_{}\".format(i) for i in range(feature_list[0].shape[0])]\n",
    ")\n",
    "\n",
    "df_final = pd.concat([df_info, df_feature], axis=1)\n",
    "print(f\"Saving features to {output_path}\")\n",
    "df_final.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ecca2c",
   "metadata": {},
   "source": [
    "## 对根目录进行批量循环提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e40258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000finished\n"
     ]
    }
   ],
   "source": [
    "# todo: 给一个父文件夹/mnt/d/3.dlProject/bdrv/data/retinal_vasculitis_crop对下面的所有子文件夹（train/val/test）及其子文件夹（bd[0]/rv[1]）来统一提取；第一列就编程第一个子文件夹；第二列就编程子子文件夹；再后面的不变\n",
    "def collect_features_from_all_subfolders(root_path, chkpt_dir, device, arch='RETFound_mae'):\n",
    "    \"\"\"\n",
    "    遍历 root_path 下所有子文件夹(例如 train/val/test)，\n",
    "    对于每个子文件夹下的子子文件夹(例如 bd/rv 等)，\n",
    "    调用原先的 get_feature(child_path, ...) 来提取特征和预测信息。\n",
    "    \n",
    "    在结果中，会额外添加 2 列：\n",
    "      - folder_1: 表示第一层子文件夹 (train / val / test 等)\n",
    "      - folder_2: 表示第二层子文件夹 (bd / rv 等)\n",
    "    最终返回一个汇总的 DataFrame。\n",
    "    \"\"\"\n",
    "    # 用来存放多个子文件夹返回的 DataFrame\n",
    "    all_dfs = []\n",
    "\n",
    "    # 1) 遍历第一级子文件夹 (train / val / test等)\n",
    "    for parent_dir_name in os.listdir(root_path):\n",
    "        parent_dir_path = os.path.join(root_path, parent_dir_name)\n",
    "        # 如果不是文件夹，就跳过\n",
    "        if not os.path.isdir(parent_dir_path):\n",
    "            continue\n",
    "        \n",
    "        # 2) 遍历第二级子文件夹 (bd / rv 等)\n",
    "        for child_dir_name in os.listdir(parent_dir_path):\n",
    "            child_dir_path = os.path.join(parent_dir_path, child_dir_name)\n",
    "            if not os.path.isdir(child_dir_path):\n",
    "                continue\n",
    "            \n",
    "            # 3) 调用之前的 get_feature (不改动原函数) 来处理这个子子文件夹\n",
    "            (\n",
    "                name_list,\n",
    "                feature_list,\n",
    "                score_raw_list,\n",
    "                prob_all_list,\n",
    "                pred_class_list,\n",
    "                pred_class_prob_list,\n",
    "                pred_1class_prob_list\n",
    "            ) = get_feature(child_dir_path, chkpt_dir, device, arch=arch)\n",
    "            \n",
    "            # 4) 构造一个用于存放 [folder_1, folder_2, name, ...] 的 DataFrame\n",
    "            df_info = pd.DataFrame({\n",
    "                \"folder_1\": [parent_dir_name] * len(name_list),  # 第一列\n",
    "                \"folder_2\": [child_dir_name] * len(name_list),   # 第二列\n",
    "                \"name\": name_list,\n",
    "                \"score_raw\": score_raw_list,\n",
    "                \"prob_all\": prob_all_list,\n",
    "                \"pred_class\": pred_class_list,\n",
    "                \"pred_class_prob\": pred_class_prob_list,\n",
    "                \"pred_1class_prob\": pred_1class_prob_list\n",
    "            })\n",
    "            \n",
    "            # 5) 把 feature_list (形如 [ [x1,...,x1024], [y1,...,y1024], ... ]) 转成 DataFrame\n",
    "            #    列名为 feature_0, feature_1, ... , feature_1023\n",
    "            df_feature = pd.DataFrame(\n",
    "                feature_list,\n",
    "                columns=[\"feature_{}\".format(i) for i in range(feature_list[0].shape[0])]\n",
    "            )\n",
    "            \n",
    "            # 6) 横向拼起来，得到包含所有列的 df_combined\n",
    "            df_combined = pd.concat([df_info, df_feature], axis=1)\n",
    "            \n",
    "            # 7) 收集到 all_dfs 里\n",
    "            all_dfs.append(df_combined)\n",
    "    \n",
    "    # 8) 把所有子文件夹的数据合并成一个总的 DataFrame\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "root_path = \"/mnt/d/3.dlProject/bdrv/data/retinal_vasculitis_crop\"\n",
    "chkpt_dir = \"/mnt/d/3.dlProject/bdrv/output/LEO/1.RETFound_mae_natureOCT0.cwflmix-bdrv/output_dir/1.RETFound_mae_natureOCT0.cwflmix-bdrv/checkpoint-best.pth\"\n",
    "output_path = \"/mnt/d/3.dlProject/bdrv/output/LEO/1.RETFound_mae_natureOCT0.cwflmix-bdrv/output_dir/1.RETFound_mae_natureOCT0.cwflmix-bdrv/feature.csv\"\n",
    "device = torch.device('cuda')\n",
    "arch = 'RETFound_mae'\n",
    "df_final = collect_features_from_all_subfolders(\n",
    "    root_path=root_path, \n",
    "    chkpt_dir=chkpt_dir, \n",
    "    device=device, \n",
    "    arch=arch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c63f866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  folder_1 folder_2                     name                   score_raw  \\\n",
      "0     test       bd  1209_2013.3.19_od_1.png  [[-0.6993152, 0.69788224]]   \n",
      "1     test       bd  1209_2013.3.19_od_2.png  [[-0.39495006, 0.3931978]]   \n",
      "2     test       bd   1517_2019.1.2_os_1.jpg   [[1.6192925, -1.6223154]]   \n",
      "3     test       bd   1517_2019.1.2_os_2.jpg   [[1.5682701, -1.5715133]]   \n",
      "4     test       bd    174_2013.8.8_od_1.png    [[1.236756, -1.2395748]]   \n",
      "\n",
      "                      prob_all  pred_class  pred_class_prob  pred_1class_prob  \\\n",
      "0     [[0.1982612, 0.8017388]]           1         0.801739          0.801739   \n",
      "1     [[0.3125665, 0.6874335]]           1         0.687433          0.687433   \n",
      "2   [[0.96237034, 0.03762962]]           0         0.962370          0.037630   \n",
      "3  [[0.95850426, 0.041495733]]           0         0.958504          0.041496   \n",
      "4   [[0.9224658, 0.077534236]]           0         0.922466          0.077534   \n",
      "\n",
      "   feature_0  feature_1  ...  feature_1014  feature_1015  feature_1016  \\\n",
      "0   0.263545   0.536434  ...      0.003460     -0.113143      0.747946   \n",
      "1   0.337975   0.465387  ...      0.164844      0.076292      0.482426   \n",
      "2   0.274933  -0.185684  ...      0.164683     -0.033518     -0.796626   \n",
      "3   0.261267  -0.639419  ...      0.189726      0.062317     -0.851804   \n",
      "4   0.308846  -0.223100  ...      0.172274      0.267487     -0.520541   \n",
      "\n",
      "   feature_1017  feature_1018  feature_1019  feature_1020  feature_1021  \\\n",
      "0      0.264173     -0.472694      1.078691     -0.299937      0.115669   \n",
      "1      0.209256     -0.073193      2.613392     -0.798834      0.331339   \n",
      "2     -0.108271      0.830621      0.721945      0.367243     -0.004558   \n",
      "3      0.006872      0.835899     -0.314946      0.382838     -0.081395   \n",
      "4      0.020942      0.690543     -0.999464      0.474611     -0.151577   \n",
      "\n",
      "   feature_1022  feature_1023  \n",
      "0     -0.113615     -0.679618  \n",
      "1     -0.226654     -0.763810  \n",
      "2     -0.097915     -0.280810  \n",
      "3     -0.195657     -0.096772  \n",
      "4     -0.099126      0.033391  \n",
      "\n",
      "[5 rows x 1032 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "746b019f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /mnt/d/3.dlProject/bdrv/output/LEO/1.RETFound_mae_natureOCT0-bdrv/output_dir/features_allfolders.csv\n"
     ]
    }
   ],
   "source": [
    "df_final.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "test",
   "name": "common-cu121.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m123"
  },
  "kernelspec": {
   "display_name": "retfound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
