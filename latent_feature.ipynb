{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae19951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import models_vit as models\n",
    "from huggingface_hub import hf_hub_download\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(chkpt_dir, arch='RETFound_mae'):\n",
    "    \n",
    "    # load model\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
    "    \n",
    "    # build model\n",
    "    if arch=='RETFound_mae':\n",
    "        model = models.__dict__[arch](\n",
    "            img_size=224,\n",
    "            num_classes=2,\n",
    "            drop_path_rate=0,\n",
    "            global_pool=True,\n",
    "        )\n",
    "        msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    else:\n",
    "        model = models.__dict__[arch](\n",
    "            num_classes=2,\n",
    "            drop_path_rate=0,\n",
    "            args=None,\n",
    "        )\n",
    "        msg = model.load_state_dict(checkpoint['teacher'], strict=False)\n",
    "    return model\n",
    "\n",
    "def run_one_image(img, model, arch):\n",
    "    \n",
    "    x = torch.tensor(img)\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    x = torch.einsum('nhwc->nchw', x)\n",
    "    \n",
    "    x = x.to(device, non_blocking=True)\n",
    "    latent = model.forward_features(x.float())\n",
    "    \n",
    "    if arch=='dinov2_large':\n",
    "        latent = latent[:, 1:, :].mean(dim=1,keepdim=True)\n",
    "        latent = nn.LayerNorm(latent.shape[-1], eps=1e-6).to(device)(latent)\n",
    "    \n",
    "    latent = torch.squeeze(latent)\n",
    "    return latent\n",
    "\n",
    "def run_one_image_for_prediction(img, model, arch): # not sure about this: 还没有写如果是dinov2_large的情况\n",
    "\n",
    "    x = torch.tensor(img)\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    x = torch.einsum('nhwc->nchw', x)\n",
    "    \n",
    "    x = x.to(device, non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(x.float())\n",
    "        probs = torch.softmax(predictions, dim=1)\n",
    "        pred_class = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "        probs_pred_class = probs[0][pred_class].item(),\n",
    "        probs_1_class = probs[0][1].item()\n",
    "    \n",
    "    return {\n",
    "        'predi predictions.cpu().numpy(), \n",
    "        'probs'      : probs.cpu().numpy(),\n",
    "        # 'predicted_class': pred_class,\n",
    "        # 'pred_class_probability': pred_class_probability,\n",
    "        # 'positive_class_probability': positive_class_probability\n",
    "    }\n",
    "    \n",
    "Can you explan the following code to me: i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427f345",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "%debug\n",
    "# model_ = prepare_model(chkpt_dir, arch)\n",
    "# model_.to(device)\n",
    "name_list = []\n",
    "feature_list = []\n",
    "pred_class_list = []  # 存储预测类别\n",
    "confidence_list = []  # 存储置信度\n",
    "model_.eval()\n",
    "\n",
    "img = Image.open(\"/mnt/d/3.dlProject/bdrv/data/retinal_vasculitis_crop/test/bd/1209_2013.3.19_od_1.png\").convert('RGB')\n",
    "\n",
    "img = img.resize((224, 224))\n",
    "\n",
    "img = np.array(img) / 255.\n",
    "\n",
    "img[...,0] = (img[...,0] - img[...,0].mean())/img[...,0].std()\n",
    "img[...,1] = (img[...,1] - img[...,1].mean())/img[...,1].std()\n",
    "img[...,2] = (img[...,2] - img[...,2].mean())/img[...,2].std()\n",
    "assert img.shape == (224, 224, 3)\n",
    "\n",
    "latent_feature = run_one_image(img, model_, arch) # latent_feature\n",
    "\n",
    "pred_result = run_one_image_for_prediction(img, model_, arch)\n",
    "pred_result['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a250363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(data_path,\n",
    "                chkpt_dir,\n",
    "                device,\n",
    "                arch='RETFound_mae'):\n",
    "    # loading model\n",
    "    model_ = prepare_model(chkpt_dir, arch)\n",
    "    model_.to(device)\n",
    "\n",
    "    img_list = os.listdir(data_path)\n",
    "    \n",
    "    name_list = []\n",
    "    feature_list = []\n",
    "    pred_class_list = []  # 存储预测类别\n",
    "    confidence_list = []  # 存储置信度\n",
    "\n",
    "    model_.eval()\n",
    "    \n",
    "    finished_num = 0\n",
    "    for i in img_list:\n",
    "        finished_num+=1\n",
    "        if (finished_num%1000 == 0):\n",
    "            print(str(finished_num)+\"finished\")\n",
    "        \n",
    "        # img = Image.open(os.path.join(data_path, i))\n",
    "        img = Image.open(os.path.join(data_path, i)).convert('RGB')\n",
    "\n",
    "        img = img.resize((224, 224))\n",
    "        img = np.array(img) / 255.\n",
    "        \n",
    "        img[...,0] = (img[...,0] - img[...,0].mean())/img[...,0].std()\n",
    "        img[...,1] = (img[...,1] - img[...,1].mean())/img[...,1].std()\n",
    "        img[...,2] = (img[...,2] - img[...,2].mean())/img[...,2].std()\n",
    "        assert img.shape == (224, 224, 3)\n",
    "        \n",
    "        latent_feature = run_one_image(img, model_, arch) # latent_feature\n",
    "\n",
    "        pred_result = run_one_image_for_prediction(img, model_, arch) # 获取预测结果\n",
    "        pred_class_list.append(pred_result['predicted_class'])\n",
    "        confidence_list.append(pred_result['confidence'])\n",
    "\n",
    "        name_list.append(i)\n",
    "        feature_list.append(latent_feature.detach().cpu().numpy())\n",
    "        \n",
    "    return [name_list, feature_list, pred_class_list, confidence_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54acfcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chkpt_dir = hf_hub_download(repo_id=\"YukunZhou/RETFound_dinov2_meh\", filename=\"RETFound_dinov2_meh.pth\")\n",
    "chkpt_dir = \"/mnt/d/3.dlProject/bdrv/output/LEO/1.RETFound_mae_natureOCT0-bdrv/output_dir/1.RETFound_mae_natureOCT0-bdrv/checkpoint-best.pth\"\n",
    "data_path = \"/mnt/d/3.dlProject/bdrv/data/retinal_vasculitis_crop/test/bd\"\n",
    "device = torch.device('cuda')\n",
    "arch='RETFound_mae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f0d13a7-2b46-40eb-ab48-5f90a6aeecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Diagnostic cell to check image formats in the dataset\n",
    "def check_image_formats(data_path, max_samples=10):\n",
    "    img_list = os.listdir(data_path)\n",
    "    if len(img_list) > max_samples:\n",
    "        img_list = img_list[:max_samples]  # Check only a few images\n",
    "    \n",
    "    print(f\"Checking up to {max_samples} images from {data_path}\")\n",
    "    for i, img_name in enumerate(img_list):\n",
    "        try:\n",
    "            img_path = os.path.join(data_path, img_name)\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            print(f\"[{i+1}] {img_name}: mode={img.mode}, shape={img_array.shape}, size={img.size}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{i+1}] {img_name}: Error - {str(e)}\")\n",
    "    \n",
    "# Run this before processing to check your images\n",
    "check_image_formats(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[name_list,feature] = get_feature(data_path, chkpt_dir, device, arch=arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925d3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the feature\n",
    "df_feature = pd.DataFrame(feature)\n",
    "df_imgname = pd.DataFrame(name_list)\n",
    "df_visualization = pd.concat([df_imgname,df_feature], axis=1)\n",
    "column_name_list = []\n",
    "\n",
    "for i in range(1024):\n",
    "    column_name_list.append(\"feature_{}\".format(i))\n",
    "df_visualization.columns = [\"name\"] + column_name_list\n",
    "# df_visualization.to_csv(\"Feature.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "test",
   "name": "common-cu121.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m123"
  },
  "kernelspec": {
   "display_name": "retfound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
